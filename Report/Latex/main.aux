\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{2}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Q-Table}{2}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Two actions lead to a win, three actions lead to a draw assuming perfect play from both sides}}{2}{}\protected@file@percent }
\newlabel{tab:perfect_Q_Table_entry}{{2.1}{2}{}{table.2.1}{}}
\newlabel{tab:perfect_Q_Table_entry@cref}{{[table][1][2]2.1}{[1][2][]2}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Q-Learning}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Q-Learning on tic-tac-toe}{4}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Generating theoretical Q-Table}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Q-Learning implementation}{4}{}\protected@file@percent }
\newlabel{modified bolztman}{{3.1}{5}{}{equation.3.1}{}}
\newlabel{modified bolztman@cref}{{[equation][1][3]3.1}{[1][5][]5}{}{}{}}
\newlabel{terminal state update}{{3.2}{5}{}{equation.3.2}{}}
\newlabel{terminal state update@cref}{{[equation][2][3]3.2}{[1][5][]5}{}{}{}}
\newlabel{non terminal state update}{{3.3}{5}{}{equation.3.3}{}}
\newlabel{non terminal state update@cref}{{[equation][3][3]3.3}{[1][5][]5}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces \textbf  {X} training against perfect \textbf  {O} causes the drawrate in the form of a decaying exponential}}{5}{}\protected@file@percent }
\newlabel{fig:x_vs_perfect_distribution_1}{{3.1}{5}{}{figure.3.1}{}}
\newlabel{fig:x_vs_perfect_distribution_1@cref}{{[figure][1][3]3.1}{[1][5][]5}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Variations in $\alpha $ and $\tau $}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Optimal and non optimal opponent}{6}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Matrix of results of agents trained on different opponents playing against each other.}}{6}{}\protected@file@percent }
\newlabel{tab:3x3_example}{{3.1}{6}{}{table.3.1}{}}
\newlabel{tab:3x3_example@cref}{{[table][1][3]3.1}{[1][6][]6}{}{}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Deep Q-Learning}{7}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Neural Network and the loss fucntion}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}cart-pole game}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}moon-landing game}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion}{8}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Bibliography}{9}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\gdef \@abspage@last{10}
