\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{2}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Q-Table}{2}{section.2.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Two actions lead to a win, three actions lead to a draw assuming perfect play from both sides}}{2}{table.2.1}\protected@file@percent }
\newlabel{tab:perfect_Q_Table_entry}{{2.1}{2}{Two actions lead to a win, three actions lead to a draw assuming perfect play from both sides}{table.2.1}{}}
\newlabel{tab:perfect_Q_Table_entry@cref}{{[table][1][2]2.1}{[1][2][]2}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Q-Learning}{2}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Q-Learning on tic-tac-toe}{4}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Generating theoretical Q-Table}{4}{section.3.1}\protected@file@percent }
\newlabel{lst:minimax}{{3.1}{4}{Minimax algorithm for generating the theoretical Q-Table}{lstlisting.3.1}{}}
\newlabel{lst:minimax@cref}{{[lstlisting][1][3]3.1}{[1][4][]4}{}{}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3.1}Minimax algorithm for generating the theoretical Q-Table}{4}{lstlisting.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Q-Learning implementation}{5}{section.3.2}\protected@file@percent }
\newlabel{modified Boltzmann}{{3.1}{5}{Q-Learning implementation}{equation.3.1}{}}
\newlabel{modified Boltzmann@cref}{{[equation][1][3]3.1}{[1][5][]5}{}{}{}}
\newlabel{terminal state update}{{3.2}{5}{Q-Learning implementation}{equation.3.2}{}}
\newlabel{terminal state update@cref}{{[equation][2][3]3.2}{[1][5][]5}{}{}{}}
\newlabel{non terminal state update}{{3.3}{5}{Q-Learning implementation}{equation.3.3}{}}
\newlabel{non terminal state update@cref}{{[equation][3][3]3.3}{[1][5][]5}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Variations in $\alpha $ and $\tau $}{5}{section.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces \textbf  {X} training against perfect \textbf  {O} causes the draw rate to increase in the form of a decaying exponential}}{6}{figure.3.1}\protected@file@percent }
\newlabel{fig:x_vs_perfect_distribution_1}{{3.1}{6}{\textbf {X} training against perfect \textbf {O} causes the draw rate to increase in the form of a decaying exponential}{figure.3.1}{}}
\newlabel{fig:x_vs_perfect_distribution_1@cref}{{[figure][1][3]3.1}{[1][5][]6}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Optimal and non-optimal opponent}{6}{section.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces \textbf  {X} training against perfect \textbf  {O} causes the \textbf  {X} win rate to increase in the form of a decaying exponential}}{7}{figure.3.2}\protected@file@percent }
\newlabel{fig:x_vs_random_distribution_1}{{3.2}{7}{\textbf {X} training against perfect \textbf {O} causes the \textbf {X} win rate to increase in the form of a decaying exponential}{figure.3.2}{}}
\newlabel{fig:x_vs_random_distribution_1@cref}{{[figure][2][3]3.2}{[1][5][]7}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Matrix of results of agents trained on different opponents playing against each other.}}{7}{table.3.1}\protected@file@percent }
\newlabel{tab:matrix of agents playing against each other}{{3.1}{7}{Matrix of results of agents trained on different opponents playing against each other}{table.3.1}{}}
\newlabel{tab:matrix of agents playing against each other@cref}{{[table][1][3]3.1}{[1][6][]7}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Theoretical Q-Table compared to RL-estimated Q-Table}{7}{section.3.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces After training \textbf  {X} on $1000$ batches of $10$ games, the highest performing values for parameters \textit  {growth rate} are $10^{\frac  {-1}{3}}$ and \textit  {decay rate} between $10^{-4}$ and $10^{-10}$}}{8}{figure.3.3}\protected@file@percent }
\newlabel{x_vs_perfect_range_of_params_1.png}{{3.3}{8}{After training \textbf {X} on $1000$ batches of $10$ games, the highest performing values for parameters \textit {growth rate} are $10^{\frac {-1}{3}}$ and \textit {decay rate} between $10^{-4}$ and $10^{-10}$}{figure.3.3}{}}
\newlabel{x_vs_perfect_range_of_params_1.png@cref}{{[figure][3][3]3.3}{[1][5][]8}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces The theoretical and RL-estimated Q-Table for x playing against perfect opponent, give similar Q-Values for explored states}}{9}{table.3.2}\protected@file@percent }
\newlabel{tab:Q-Table comparison for ____o_oxx}{{3.2}{9}{The theoretical and RL-estimated Q-Table for x playing against perfect opponent, give similar Q-Values for explored states}{table.3.2}{}}
\newlabel{tab:Q-Table comparison for ____o_oxx@cref}{{[table][2][3]3.2}{[1][8][]9}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.3}{\ignorespaces The theoretical Q-Table for x playing against a random opponent, and RL-estimated Q-Table for x playing against a random opponent give different values, because the future policy is different}}{9}{table.3.3}\protected@file@percent }
\newlabel{tab:Q-Table comparison for _______ox}{{3.3}{9}{The theoretical Q-Table for x playing against a random opponent, and RL-estimated Q-Table for x playing against a random opponent give different values, because the future policy is different}{table.3.3}{}}
\newlabel{tab:Q-Table comparison for _______ox@cref}{{[table][3][3]3.3}{[1][8][]9}{}{}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Deep Q-Learning}{10}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Neural Network structure, backpropagation, cost function}{10}{section.4.1}\protected@file@percent }
\newlabel{eq:forward propagation}{{4.1}{10}{Neural Network structure, backpropagation, cost function}{equation.4.1}{}}
\newlabel{eq:forward propagation@cref}{{[equation][1][4]4.1}{[1][10][]10}{}{}{}}
\newlabel{eq:target}{{4.2}{11}{Neural Network structure, backpropagation, cost function}{equation.4.2}{}}
\newlabel{eq:target@cref}{{[equation][2][4]4.2}{[1][10][]11}{}{}{}}
\newlabel{eq:loss function}{{4.3}{11}{Neural Network structure, backpropagation, cost function}{equation.4.3}{}}
\newlabel{eq:loss function@cref}{{[equation][3][4]4.3}{[1][11][]11}{}{}{}}
\newlabel{lst:backprop}{{4.1}{11}{Backpropagation implementation for Q-Learning}{lstlisting.4.1}{}}
\newlabel{lst:backprop@cref}{{[lstlisting][1][4]4.1}{[1][11][]11}{}{}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4.1}Backpropagation implementation for Q-Learning}{11}{lstlisting.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Deep Q-Learning results}{11}{section.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The library I made is able to train a neural network to control a cart balancing a pole. The neural network takes in 4 parameters and generates 2 q-values.}}{12}{figure.4.1}\protected@file@percent }
\newlabel{fig:CartPole-v1_example.png}{{4.1}{12}{The library I made is able to train a neural network to control a cart balancing a pole. The neural network takes in 4 parameters and generates 2 q-values}{figure.4.1}{}}
\newlabel{fig:CartPole-v1_example.png@cref}{{[figure][1][4]4.1}{[1][11][]12}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces The library I made is able to train a neural network to control a spaceship landing on the moon. The neural network takes in 8 parameters and generates 4 q-values.}}{12}{figure.4.2}\protected@file@percent }
\newlabel{fig:LunarLander-v3_example.png}{{4.2}{12}{The library I made is able to train a neural network to control a spaceship landing on the moon. The neural network takes in 8 parameters and generates 4 q-values}{figure.4.2}{}}
\newlabel{fig:LunarLander-v3_example.png@cref}{{[figure][2][4]4.2}{[1][11][]12}{}{}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusion}{13}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Appendices}{14}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Declaration}{14}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Code}{14}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}References}{14}{section.6.3}\protected@file@percent }
\gdef \@abspage@last{15}
