{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "This notebook uses the q_learning_lib.py to perform Q-learning on tic tac toe.\n",
    "\n",
    "A variation of different hyperparameters are tried, against many different cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import q_learning_lib as qlb\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Assuming alpha = 0.1 and tau = e, lets record what happens in each of the 4 cases of training (optimal, non optimal, x, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_BATCHES = 500\n",
    "BATCH_SIZE = 10\n",
    "NUMBER_OF_GAMES = NUMBER_OF_BATCHES * BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_alpha(rate_val):\n",
    "    \"\"\"Function factorie for creating different alpha functions\"\"\"\n",
    "    def alpha(turn):\n",
    "\n",
    "        #return rate_val * (BATCH_SIZE * NUMBER_OF_BATCHES - turn) / (NUMBER_OF_BATCHES * BATCH_SIZE)\n",
    "        #return 0.5 / (1 + rate_val * turn) \n",
    "\n",
    "        return 0.5 * np.exp(-rate_val * turn) #my new proposed fucntion\n",
    "\n",
    "    return alpha\n",
    "\n",
    "def make_tau(rate_val):\n",
    "    \"\"\"Function factorie for creating different tau functions\"\"\"\n",
    "    def tau(turn):\n",
    "        #return 1 + max_rate * (turn) / (NUMBER_OF_BATCHES * BATCH_SIZE) \n",
    "        #return 1 + (max_rate - 1) * ((turn/(NUMBER_OF_BATCHES * BATCH_SIZE))**3)\n",
    "        return np.pow(10000, np.pow(turn/(NUMBER_OF_GAMES), rate_val )) #my new proposed function\n",
    "\n",
    "    return tau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def record_params(results, filename):\n",
    "\n",
    "    df = pd.DataFrame(results[::-1], columns=['o_win', 'draw', 'x_win'])\n",
    "\n",
    "    # Save to CSV (index=False prevents it from adding a row-number column)\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_exponents = np.linspace(-4, -10, 10)\n",
    "alpha_values = np.pow(10, alpha_exponents)\n",
    "tau_exponents = np.linspace(-3, 3, 10 )\n",
    "tau_values = np.pow(10, tau_exponents)\n",
    "print(alpha_values)\n",
    "print(tau_values)\n",
    "print(tau_exponents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "x = np.arange(0, len(alpha_values))\n",
    "\n",
    "axes.plot(x, alpha_values)\n",
    "#axes.plot(x, tau_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_different_hyperparams(alpha_rates, tau_rates, player, strategy, folder=\"\"):\n",
    "    \"\"\"this functions tries a variation of different hyperparameters\n",
    "    results from every single iteration are saved in a .csv file\n",
    "    how alpha params, tau values affect the final winrates is recorded in a pandas df and also saved to a file \"\"\"\n",
    " \n",
    "    df_list = [] #will be turned to a df later\n",
    "    \n",
    "    for a, alpha_rate in enumerate(alpha_rates): \n",
    "        for b, tau_rate in enumerate(tau_rates):\n",
    "\n",
    "            #trains\n",
    "            Q_Table_x_optimal, results = qlb.perform_training(player, strategy, NUMBER_OF_BATCHES, BATCH_SIZE, False, make_alpha(alpha_rate), make_tau(tau_rate))\n",
    "\n",
    "            results = results/(BATCH_SIZE * 50)\n",
    "        \n",
    "            #records the resultsplayer_x_label='x', player_o_label='o', \n",
    "            filename = f\"parameter_results/{player}_vs_{strategy}/_opponent_alpha_{alpha_rate}_tau_{tau_rate}.csv\"\n",
    "            record_params(results, filename)\n",
    "\n",
    "            \n",
    "            #records end winrates vs hyperparams\n",
    "            o_winrate = np.mean(results[:, 0][-5:])\n",
    "            drawrate = np.mean(results[:, 1][-5:])\n",
    "            x_winrate = np.mean(results[:, 2][-5:])\n",
    "            new_results = {'alpha_rate': alpha_rate, 'tau_rate': tau_rate, 'o_winrate': o_winrate, 'drawrate': drawrate, 'x_winrate': x_winrate}\n",
    "            df_list.append(new_results)\n",
    "\n",
    "            print(f\"{player}_vs_{strategy}: {((a * 10 + b + 1)/(len(alpha_rates) * len(tau_values))) * 100:.2f}%\")\n",
    "            print(f\"'alpha_rate' {alpha_rate}, 'tau_rate': {tau_rate}, 'o_winrate': {o_winrate:.3f}, 'drawrate': {drawrate:.3f}, 'x_winrate': {x_winrate:.3f}\")\n",
    "\n",
    "    df = pd.DataFrame(df_list) \n",
    "    df.to_csv(f\"parameter_results/{player}_vs_{strategy}/hyperparams.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try_different_hyperparams(alpha_values, tau_values, 'x', 'perfect')\n",
    "#try_different_hyperparams(alpha_values, tau_values, 'o', 'perfect')\n",
    "#try_different_hyperparams(alpha_values, tau_values, 'x', 'random')\n",
    "#try_different_hyperparams(alpha_values, tau_values, 'o', 'random')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('parameter_results/analysis_4/x_vs_random/hyperparams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Filter data\n",
    "mask = df[np.log10(df['tau_rate']) < 1]\n",
    "\n",
    "x = np.log10(mask['alpha_rate'])\n",
    "y = np.log10(mask['tau_rate'])\n",
    "z = mask['x_winrate']\n",
    "\n",
    "# 2. Plotting\n",
    "scatter = ax.scatter(x, y, c=z, s=1600, cmap='viridis', marker='s') # marker='s' often looks better for grid searches\n",
    "\n",
    "# --- THE FORMATTING PART ---\n",
    "def log_formatter(x, pos):\n",
    "    return f\"$10^{{{int(x)}}}$\"\n",
    "\n",
    "# Apply formatter to X axis\n",
    "ax.xaxis.set_major_formatter(ticker.FuncFormatter(log_formatter))\n",
    "# Apply formatter to Y axis\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(log_formatter))\n",
    "\n",
    "# Ensure ticks stay at integer intervals (prevents 10^-4.5)\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "ax.yaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "# ---------------------------\n",
    "\n",
    "# 3. Colorbar and Labels\n",
    "cbar = fig.colorbar(scatter, ax=ax)\n",
    "cbar.set_label(z.name, size=14)\n",
    "\n",
    "# Use LaTeX for the Greek letters alpha and tau\n",
    "ax.set_xlabel(r'decay rate', fontsize=14)\n",
    "ax.set_ylabel(r'growth rate', fontsize=14)\n",
    "ax.set_title(f\"Max {z.name} achieved {z.max() * 100 :.2f}%\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "I have found good parameters for alpha rate and tau rate which should be implemented:\n",
    "\n",
    "alpha_rate 10^-7\n",
    "\n",
    "tau_rate = 10^-0.333\n",
    "\n",
    "\n",
    "Now the goal is to create a matrix:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Agent      | O Pefrect   |    O Random \n",
    "           |             |              \n",
    "X Perfect  |             |                  \n",
    "-----------|- -----------|----------------- \n",
    "X Random   |             |  \n",
    "           |             |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "I will train 4 models on those parameters and record the results after playing 1000 games against each other using tau as the softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = make_alpha(np.pow(10.0, -7))\n",
    "tau = make_tau(np.pow(10.0, -1/3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Q_Table_X_Perfect, results = qlb.perform_training('x', 'perfect', NUMBER_OF_BATCHES, BATCH_SIZE, False, alpha, tau)\n",
    "print(results[-1, :])\n",
    "Q_Table_X_Random, results = qlb.perform_training('x', 'random', NUMBER_OF_BATCHES, BATCH_SIZE, False, alpha, tau)\n",
    "print(results[-1, :])\n",
    "Q_Table_O_Perfect, results = qlb.perform_training('o', 'perfect', NUMBER_OF_BATCHES, BATCH_SIZE, False, alpha, tau)\n",
    "print(results[-1, :])\n",
    "Q_Table_O_Random, results = qlb.perform_training('o', 'random', NUMBER_OF_BATCHES, BATCH_SIZE, False, alpha, tau)\n",
    "print(results[-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[-1, :]/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_Table_X_Random, results = qlb.perform_training('x', 'random', NUMBER_OF_BATCHES, BATCH_SIZE, True, alpha, tau, 30)\n",
    "qlb.plot_training_results(results, BATCH_SIZE, NUMBER_OF_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q_Table_X_Perfect[\"_________\"]\n",
    "Q_Table_X_Perfect[\"____o_oxx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_of_games_in_the_match = 10000\n",
    "results_x_perfect_vs_o_perfect = qlb.Q_Table_match(Q_Table_X_Perfect, Q_Table_O_Perfect, number_of_games_in_the_match, 'softmax', 100)\n",
    "#results_x_perfect_vs_o_random = qlb.Q_Table_match(Q_Table_X_Perfect, Q_Table_O_Random, number_of_games_in_the_match, 'softmax', 10)\n",
    "#results_x_random_vs_o_perfect = qlb.Q_Table_match(Q_Table_X_Random, Q_Table_O_Perfect, number_of_games_in_the_match, 'softmax', 10)\n",
    "#results_x_random_vs_o_random = qlb.Q_Table_match(Q_Table_X_Random, Q_Table_O_Random, number_of_games_in_the_match, 'softmax', 10)\n",
    "#results_fully_random_game = qlb.Q_Table_match(Q_Table_X_Perfect, Q_Table_O_Perfect, number_of_games_in_the_match, 'softmax', 1)\n",
    "#results_another_fully_random_game = qlb.play_random_match(number_of_games_in_the_match)\n",
    "\n",
    "#results_from_matches = [results_x_perfect_vs_o_perfect, results_x_perfect_vs_o_random, results_x_random_vs_o_perfect, results_x_random_vs_o_random, results_fully_random_game, results_another_fully_random_game]\n",
    "\n",
    "#for result_from_match in results_from_matches:\n",
    "    \n",
    " #   print(result_from_match/np.sum(result_from_match))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_x_perfect_vs_o_perfect/np.sum(results_x_perfect_vs_o_perfect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "**Final results are:**\n",
    "\n",
    "[0.2699  0.1412 0.5889]\n",
    "\n",
    "[0.6103 0.2324 0.1573]\n",
    "\n",
    "[0.0559 0.0836 0.8605]\n",
    "\n",
    "[0.2667 0.3002 0.4331]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "***Next stage is to compare the theoretically generated Q-Tables and the actual Q-Table that was made during learning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing perfect Q-Tables\n",
    "\n",
    "perfect_theoretical_Q_Table = qlb.import_perfect_Q_Table()\n",
    "\n",
    "perfect_theoretical_Q_Table['____o_oxx']\n",
    "\n",
    "for state in perfect_theoretical_Q_Table:\n",
    "    \n",
    "    if state.count(\"_\") % 2 == 1:\n",
    "        \n",
    "        if qlb.check_result(state) == 2:\n",
    "\n",
    "            print(state)\n",
    "            print(perfect_theoretical_Q_Table[state])\n",
    "            print(Q_Table_X_Perfect[state])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing random Q-Tables\n",
    "\n",
    "random_theoretical_Q_Table = qlb.import_perfect_Q_Table(\"data_exports/random_Q_Table.json\")\n",
    "\n",
    "for state in random_theoretical_Q_Table:\n",
    "    \n",
    "    if state.count(\"_\") % 2 == 1:\n",
    "        \n",
    "        if qlb.check_result(state) == 2:\n",
    "\n",
    "            print(state)\n",
    "            print(random_theoretical_Q_Table[state])\n",
    "            print(Q_Table_X_Random[state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_theoretical_Q_Table['____o_oxx']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Good results, I have implemented that into my report. Now I will generate some graphs for report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No Learning over 1000 batches of 10 (hyperparameter tau = 1, alpha = 0, means that )\n",
    "\n",
    "qlb.plot_training_results(results, BATCH_SIZE, NUMBER_OF_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[:, 0]/(366+134) < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train via Q-Learning (Existing)\n",
    "q_table_td, results_td = qlb.perform_training('x', opponent_type='random', number_of_batches=NUMBER_OF_BATCHES, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Train via Monte Carlo (New)\n",
    "q_table_mc, results_mc = qlb.perform_training_MC_incremental('x', opponent_type='random')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot and compare\n",
    "qlb.plot_training_results(results_td, BATCH_SIZE, NUMBER_OF_BATCHES)\n",
    "qlb.plot_training_results(results_mc, BATCH_SIZE, NUMBER_OF_BATCHES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
